# Requirements and Configuration

## Software Requirements

- Python (tested with version 3.9.5)
  + Modules: shapely, psycopg2, tifffile
- GDAL/ORG (comes installed with QGIS or can install standalone)
- PostgreSQL/PostGIS database

## Configuration

All configuration is setup in the ``config.ini`` file. Before running any scripts you should ensure the information in this file is correct.

All of the scripts allow for a custom configuration file to be specified by providing it as the ``-c`` argument to the program. If not supplied, the default ``config.ini`` file will be used. For example:

``prompt> create_db.py -c custom_config.ini``

### Configuration File Definitions {.unnumbered}

```
[OGR]
ogr = location of ogr2ogr executable
gdalinfo = location of gdalinfo executable
gdalsrsinfo = location of gdalsrsinfo executable
proj = optional location of proj library

[DATABASE]
host = database host
port = database post
name = database name
user = database username
password = database password
data_schema = name of main schema for holding raw stream data
stream_table = names of streams table
fish_species_table = name of fish species table
working_srid = the srid (3400) of the stream data - these scripts use the function st_length to compute stream length so the raw data should be in a meters based projection (or reprojected before used)
aquatic_habitat_table = table name for fish aquatic habitat data
fish_stocking_table = table name for fish stocking data
fish_survey_table = table name for fish survey data

[CABD_DATABASE] - the barriers database for loading barrier data
host = CABD host name
port = CABD port
name = CABD database name
user = CABD username
password = CABD password
buffer = this is the buffer distance to grab features - the units are in the working_srid so if its meters 200 is reasonable, if it's degrees something like 0.001 is reasonable
snap_distance = distance (in working srid units) for snapping point features #to the stream network (fish observation data, barrier data etc)

[CREATE_LOAD_SCRIPT]
raw_data = raw alberta data
road_table = road table name
rail_table = rail table name
trail_table = trail table name

[PROCESSING]
stream_table = stream table name

[WATERSHEDID 1] -> there will be one section for each watershed with a unique section name
watershed_id = watershed id to process
output_schema = output schema name
fish_observation_data = zip file containing fish observation data

[WATERSHEDID 2] -> there will be one section for each watershed with a unique section name
watershed_id = watershed id to process
output_schema = output schema name
fish_observation_data = zip file containing fish observation data

[ELEVATION_PROCESSING]
dem_directory = directory containing dem
3dgeometry_field = field name (in streams table) for geometry that stores raw elevation data
smoothedgeometry_field = field name (in streams table) for geometry that stores smoothed elevation data

[MAINSTEM_PROCESSING]
mainstem_id = name of mainstem id field (in streams table)
downstream_route_measure = name of downstream route measure field
upstream_route_measure =name upstream route measure field

[GRADIENT_PROCESSING]
vertex_gradient_table = table for storing vertex gradient values
segment_gradient_field = name of segment gradient field (in streams table)
max_downstream_graident_field = name of field for storing the maximum downstream segment gradient (in streams table)

[BARRIER_PROCESSING]
barrier_table = table for storing barriers

[MODELLED_CROSSINGS]
modelled_crossings_table = table for storing modelled crossings
strahler_order_barrier_limit = all crossings on streams with strahler order less than this will be considered barriers and treated similar to dams/waterfalls for habitat modelling

[HABITAT_STATS]
stats_table = this table will be created in the [DATABASE].data_schema schema and contain watershed statistics

watershed_data_schemas=ws17010302,ws17010301 --> this is the list of processing schemas to include in the stats the schemas must exist and data must be processed
```