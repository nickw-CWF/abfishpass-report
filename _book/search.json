[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Berland-Wildhay Watershed Connectivity Remediation Planning",
    "section": "",
    "text": "A special thank you to Refractions Research Inc. for their technical expertise in developing the abfishpass tools.↩︎"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Purpose",
    "section": "",
    "text": "abfishpass is a suite of decision-support tools to help guide locally-driven, watershed-scale barrier remediation work in Alberta. The model framework builds on an extensive body of knowledge on how to quantify the connectivity of freshwater systems, as well as methods to prioritize barriers for remediation. By integrating freshwater connectivity and barrier prioritization modelling into the Watershed Connectivity Remediation Planning (WCRP) process, decision-makers can account for the considerable logistic and socioeconomic factors that influence connectivity remediation decision making, and link the results of the model outputs to on-the-ground implementation of remediation actions.\nThe abfishpass tools will help quantify and update the connectivity context of a given watershed, forecast where best to take action to efficiently achieve the WCRP goals, and track progress over time. Ultimately, the goal is to support decision making around the strategic allocation of limited barrier-remediation resources by prioritizing those barriers that will provide the greatest ecological return-on-investment, thus providing an alternative to the opportunistic approach to barrier remediation. See Section 4: Supporting Spatial Analyses of the Watershed Connectivity Remediation Planning practitioners’ guide for more information on how connectivity modelling supports planning and decision making.\nabfishpass v1.0 provides tools to (more details contained in subsequent sections):\n\nImport and load required datasets to an open-source database Complete 1\nCalculate elevation and slope of the stream network Complete\nGenerate modelled stream crossings and match barrier inspection data to corresponding modelled points Complete 2\nModel gradient barriers, accessibility, and potential habitat Pending 3\nPrioritize barriers based on upstream habitat length (both total and functional networks) Complete\nCalculate overall connectivity status of the watershed Complete\n\n\n\n\n\n\nTools are complete; however, full data release is pending data-sharing agreements for watercourse crossing inspection data.↩︎\nTools are complete; however, full data release is pending data-sharing agreements for watercourse crossing inspection data.↩︎\nGradient barrier and accessibility modelling is complete. Habitat modelling could not be completed due to the lack of existing literature to support derived thresholds for gradient and discharge for useable habitat (i.e., spawning and rearing) for target species. Pending expert input on parameter thresholds for habitat modelling.↩︎"
  },
  {
    "objectID": "model-overview.html",
    "href": "model-overview.html",
    "title": "2  Approach",
    "section": "",
    "text": "abfishpass is a decision-support tool intended to compliment the watershed connectivity remediation planning process (see the report for Activity 2: Deliver Watershed Connectivity Planning Framework and Associated Decision-Support Tools and Planning Exercises), and the decisions made during the planning workshops with partners will influence the inputs, parameters, and outputs of the spatial models. This collaborative method blend local stakeholder and rightsholder knowledge with innovative GIS analyses to gain a shared understanding of where remediation efforts will have the greatest benefit for fish. The primary steps in the spatial modelling approach are:\nabfishpass is designed to be flexible to allow users to customize the selection of geographic scope (usually watersheds), target species, and barrier types that feed into the model tools. Currently, the tools only support modelling of longitudinal connectivity (i.e., upstream-downstream), but we hope to expand the tools to support other dimensions of connectivity (e.g., lateral connectivity) in the future. WCRPs are intended to be “living plans” that are updated regularly as new information becomes available, or if local priorities and contexts change, which requires easily updated and run spatial models, which abfishpass aims to achieve."
  },
  {
    "objectID": "model-overview.html#define-the-geographic-scope",
    "href": "model-overview.html#define-the-geographic-scope",
    "title": "2  Approach",
    "section": "2.1 Define the geographic scope",
    "text": "2.1 Define the geographic scope\nSimply, this is setting the geographic extent for analysis to focus the scope of the project, i.e., placing a polygon around the project area. All streams and barriers within the geographic extent are in scope, everything else is out of scope. The geographic scope is generally a watershed boundary, but can also be other types of geographic areas, including species-at-risk distribution areas and Indigenous traditional territory boundaries.\nIn Alberta, the Hydrologic Unit Code (HUC) system is used to define watersheds at various scales. Generally, abfishpass should be used with HUC4, HUC6, or HUC8 watersheds."
  },
  {
    "objectID": "model-overview.html#define-the-thematic-scope",
    "href": "model-overview.html#define-the-thematic-scope",
    "title": "2  Approach",
    "section": "2.2 Define the thematic scope",
    "text": "2.2 Define the thematic scope\nConnectivity is a critical component of freshwater ecosystems that encompasses a variety of factors related to ecosystem structure and function, such as the ability of aquatic organisms to disperse and/or migrate, the transportation of energy and matter (e.g., nutrient cycling and sediment flows), and temperature regulation. Though each of these factors are important when considering the health of a watershed, for the purposes of WCRPs the term “connectivity” is generally defined as the degree to which aquatic species can disperse and/or migrate freely through freshwater systems. WCRPs are intended to focus on the direct remediation and prevention of localized, physical barriers instead of the broad land-use patterns that are causing chronic connectivity issues in the watershed, which differentiates this process from traditional watershed or fish habitat restoration plans). As such, defining the thematic scope of “connectivity” helps determine key parameters for spatial modelling, and comprises three main concepts:\n\nTarget species\nDimensions of connectivity\nBarrier types\n\n\nTarget species\nThe choice of which target species to select will depend on several factors, such as funding source priorities, the availability of species-distribution data to inform the spatial analyses, and the ecological and cultural priorities of the team. Some time target species can be combined into groups or “guilds” to simplify the planning and spatial modelling processes (e.g., Coldwater Salmonids for the Berland-Wildhay project).\nThe selection of target species will inform spatial modelling in two ways:\n\nLife history characteristics - the way species move through freshwater systems will help determine which barriers effect their movements and the way we quantify the connectivity status of the watershed (see Table 1).\nHabitat use - the geomorphic characteristics of a stream reach the is suitable for spawning, rearing, or other life stages will vary by species (see Estimate watershed accessibility and habitat distribution).\n\n\nTable 1. Typical life history characteristics of freshwater species.\n\n\n\n\n\n\nLife history\nDescription\n\n\n\n\nDiadromous\nSpecies that migrate between the ocean and freshwater to complete their life cycles. These include species that spawn in freshwater and migrate to the ocean (anadromous) and vice versa (catadromous).\n\n\nAdfluvial\nSpecies that migrate between lakes or reservoirs and rivers.\n\n\nFluvial\nSpecies that migrate between mainstem rivers and tributaries.\n\n\nResident\nSpecies that typically spend their entire life cycle near where they hatched, though may occasionally disperse\n\n\n\n\n\nDimensions of connectivity\nThere are four widely recognized dimensions of structural connectivity of freshwater systems (see Table 2), each of which will be impacted by different barrier types and therefore creates different analysis needs for spatial modelling.\n\nTable 2. The four structural dimension of freshwater connectivity.\n\n\n\n\n\n\nConnectivity dimension\nDescription\n\n\n\n\nLongitudinal\nConnectivity of a stream along the upstream-downstream plane (Figure 1), including access to tributaries and spawning and rearing habitat. Longitudinal connectivity can be fragmented by physical barriers (e.g., anthropogenic or natural structures) or by physiological limits of distribution for species (e.g., stream gradient, temperature, or flow requirements).\n\n\nLateral\nConnectivity of a stream bed to adjacent riparian wetlands and floodplains (Figure 1), including access to rearing and overwintering habitat. Lateral connectivity can be fragmented by physical barriers, channelization, armouring of the stream bed, or artificial flow regulation.\n\n\nVertical\nConnectivity of a stream bed to groundwater/hyporheic zone (Figure 1), including access to oxygen-rich temperature refugia. Vertical connectivity can be fragmented by water withdrawals and anthropogenically induced changes to the hydrological, thermal, and sediment regimes of the watershed.\n\n\nTemporal\nConnectivity variability in any of the three spatial dimensions based on temporal changes in the natural flow regime. Variation in temporal connectivity occurs naturally; however, fragmentation can be exacerbated through anthropogenically induced changes to the hydrological, thermal, and sediment regimes of the watershed.\n\n\n\nSince the WCRP process and supporting spatial models focus on the direct remediation and prevention of localized, physical barriers to connectivity, the structural dimensions that WCRPs will typically focus on are longitudinal and lateral, because 1) fragmentation to those dimensions of connectivity can be more directly tied to physical barriers and 2) field assessment, remediation planning, and barrier prioritization methods are further developed for them. Nonetheless, it is recommended that vertical and temporal connectivity still be accounted for in the planning process and spatial modelling because vertical and temporal factors can influence the success of remediation actions. For example:\n\nLongitudinal and lateral barriers may be passable to fish at certain times of the year, but alignment of passability timing with the needs of each life history stage must be considered when prioritizing barriers for remediation (e.g., juvenile migration to rearing habitat).\nVertical connectivity issues may need to be addressed in conjunction with remediating longitudinal or lateral barriers (e.g., installing beaver-dam analogues in conjunction with dyke breaching to expand the area of groundwater influence and cold water refugia).\n\n\n\n\nFigure 1. An illustration of the three spatial dimensions of freshwater structural connectivity.\n\n\n\n\n\n\n\n\nNote\n\n\n\nCurrently, abfishpass only supports modelling of longitudinal connectivity, but we hope to expand the tools to support lateral connectivity in the future.\n\n\n\n\nBarrier types\nWithin the context of WCRPs, connectivity is primarily constrained by physical barriers, including anthropogenic infrastructure such as dams, weirs, and stream crossings, and natural features such as waterfalls. The selection of dimensions of connectivity on which to focus will influence which barrier types are selected to include in the planning process and spatial models (see Table 3).\n\nTable 3. A non-exhaustive list of common barrier classes, barrier types, and their respective connectivity dimensions.\n\n\n\n\n\n\n\nBarrier Class\nBarrier Types\nSpatial Connectivity Dimensions\n\n\n\n\nWater-control structures\nDams\nLongitudinal\n\n\n\nWeirs\nLongitudinal\n\n\n\nWater-withdrawal structures\nVertical\n\n\nFlood-mitigation infrastructure\nTide gates, aboiteaux\nLongitudinal, lateral\n\n\n\nPump stations\nVertical\n\n\nStream crossings\nRoad-stream crossings\nLongitudinal\n\n\n\nRail-stream crossings\nLongitudinal\n\n\n\nTrail-stream crossings\nLongitudinal\n\n\nLateral\nDykes/levees\nLateral\n\n\n\nRoads, rail lines\nLongitudinal/lateral\n\n\n\nBerms, embankments\nLateral\n\n\nNatural\nWaterfalls\nLongitudinal\n\n\n\nDebris jams (e.g., rocks, logs)\nLongitudinal\n\n\n\nSediment wedges\nLongitudinal/lateral\n\n\nPhysiological\nGradient\nLongitudinal\n\n\n\nFlow\nLongitudinal, vertical\n\n\n\nTemperature\nVertical/longitudinal\n\n\n\nAdditionally, it will be necessary for spatial modelling to compile information and data on barrier types that are not under consideration for remediation. For example, it is useful to incorporate natural barriers (e.g., waterfalls) into the spatial models to more accurately quantify the availability of habitat in the watershed, even though we don’t want to consider waterfalls for remediation. Barrier data will be overlaid on the stream network during analysis to allow for quantification of the amount of habitat potentially blocked by individual structures (which is the basis for barrier prioritization) and for estimating the overall connectivity status of the watershed.\nCurrently, abfishpass supports the following barrier types:\n\nDams\nStream crossings (road, rail, and trail)\nWaterfalls\nGradient barriers"
  },
  {
    "objectID": "model-overview.html#estimate-watershed-accessibility-and-habitat-distribution",
    "href": "model-overview.html#estimate-watershed-accessibility-and-habitat-distribution",
    "title": "2  Approach",
    "section": "2.3 Estimate watershed accessibility and habitat distribution",
    "text": "2.3 Estimate watershed accessibility and habitat distribution\nOnce the geographic and thematic scope have been defined, the steps are in place to derive the necessary parameters and perform the spatial analyses. The foundation for freshwater connectivity modelling, including abfishpass, are analyses to calculate key parameters within the hydrographic networks (i.e., spatial representation of streams/rivers and lakes). This involves “draping” the stream network over digital elevation models (DEMs) and developing or incorporating other models to derive key geomorphic characteristics of the stream network.\nThere are two primary steps to this process:\n\nCalculate accessibility of streams in the watershed\nDefine useable habitat distribution\n\n\nStream Accessibility\nDefining stream accessibility relies on incorporating natural (e.g., waterfall) and physiological (e.g., gradient barrier) data into spatial models - we don’t want to prioritize barriers for remediation that target species cannot naturally access. The goal of this step is to define the accessibility values of each stream segment in the watershed, which can be categorized as:\n\nPotentially accessible: the stream segment should be accessible to target species in the absence of anthropogenic barriers\nNot accessible: the stream segment is not accessible to target species, even in the absence of anthropogenic barriers (i.e., there is a natural barrier like a waterfall or gradient barrier)\nAccessible: the stream segment is potentially accessible and is downstream of any known anthropogenic barriers\n\nWaterfall data may need field verification as part of the iterative barrier prioritization process, as some species can pass waterfalls of a certain height (e.g., Chinook Salmon can pass waterfalls up to 5 m in height) and therefore some waterfalls may not be barriers to fish passage.\nIdentifying gradient barriers requires the derivation of gradient values from the elevation changes of the stream network. Different target species will have different swimming abilities, and therefore identify stream reaches that have sustained gradient values above a given species’ passability thresholds is important to exclude non-accessible streams from further analysis steps.\nAccessibility is also dependent on species life history strategies, for example, a 5 m waterfall will restrict potentially accessible stream for anadramous species (they cannot move upstream of the waterfall during their migration). But, for a system with fluvial or resident species, there may exist population both upstream and downstream of the waterfall, meaning that the stream segments upstream of the waterfall should still be considered potentially accessible, as long as species presence is verifiable upstream of the waterfall.\nFor example, for fluvial species with a gradient barrier threshold set to 35% and target species observations upstream of a given “barrier”:\n\n\n\nFigure 2. A conceptual example of defining stream segment accessibility.\n\n\n \nAssigning accessibility values refines the geographic scope of the analysis for subsequent steps – modelled habitat will not be considered and barriers will not be prioritized for not accessible streams. This allows resources to be focused on the parts of the watershed that will most benefit target species.\n\n\nModel Potential Habitat\nWhile calculating stream accessibility helps refine the scope for analysis, it does not guarantee that accessible and potentially accessible streams will support useable habitat (e.g., spawning, rearing, or overwintering habitat) for target species. During the connectivity status assessment and barrier prioritization process, we want to ensure that we are focusing on the quantity of potential useable habitat, rather than total stream length. For example, a barrier that is blocking 2 km of spawning habitat should be prioritized over a barrier that is blocking 200 m of spawning habitat and 5 km of non-habitat.\nTo model potential habitat in the watershed, abfishpass adapts the Intrinsic Potential (IP) habitat modelling framework (see Sheer et al. 2009). The IP framework derives three key geomorphic parameters of stream segments, which are used to assign potential habitat values:\n\nGradient\nDischarge\nChannel confinement (the ratio of channel width to valley/floodplain width)\n\nThe framework can be custimized to model individual habitat types (e.g., spawning vs. rearing) separately for each species. The IP model is not intended to replace field assessment, but rather acts as a decision-support tool to identify the stream segments in the watershed that are most likely to support useable habitat, which feeds into the iterative barrier prioritization process.\nUnfortunately, after undertaking a thorough literature review, the supporting information does not exist to derive thresholds for each IP parameter for Coldwater Salmonid species in Alberta for the Berland-Wildhay Connectivity Remediation Planning project. Nonetheless, the abfishpass tools have been developed to support the required inputs for the IP framework for when we are able to derive species-specific thresholds for each parameter. AWC, AEP, and CWF will work with species experts to begin deriving these parameter thresholds. When in place the model will evaluate whether a stream segment falls within the minimum and maximum values for stream gradient, discharge, and channel confinement. This will help refine upstream habitat estimates for each barrier in the watershed.\nIn the absence of IP inputs, all >1 order stream segments are considered to be “potential habitat” in barrier prioritization and connectivity status calculations."
  },
  {
    "objectID": "model-overview.html#quantify-current-connectivity-status-of-the-watershed",
    "href": "model-overview.html#quantify-current-connectivity-status-of-the-watershed",
    "title": "2  Approach",
    "section": "2.4 Quantify current connectivity status of the watershed",
    "text": "2.4 Quantify current connectivity status of the watershed\nTo inform the goal setting and barrier prioritization components of the WCRP process, it is necessary to quantify an estimate of the current connectivity status of the watershed. This will rely on the best available information, and can be updated over time as new data is collected (e.g., field inspections of modelled crossings).\nTo calculate the current connectivity status of the watershed it is necessary to overlay the barriers on the stream network (with accessibility and habitat already modelled). The tools will calculate the current status of a watershed by dividing the amount of potential habitat that is currently accessible (i.e., downstream of known anthropogenic barriers) by the total amount of potential habitat in the watershed.\n\\(Connectivity\\;status = \\frac{Accessible\\;potential\\;habitat}{Total\\;potential\\;habitat}\\)\nThis status is used to inform goal-setting and track progress over time in the watershed connectivity remediation planning process."
  },
  {
    "objectID": "model-overview.html#undertake-barrier-prioritization",
    "href": "model-overview.html#undertake-barrier-prioritization",
    "title": "2  Approach",
    "section": "2.5 Undertake barrier prioritization",
    "text": "2.5 Undertake barrier prioritization\nBarriers will be prioritized based on those that will provide the greatest ecological benefit (i.e., will reconnect the greatest amount of habitat, if remediated). The upstream functional network (i.e., the amount of habitat upstream of the barrier in question, but downstream of all subsequent upstream barriers) will be calculated to inform the prioritization (see Figure 3).\n\n\n\nFigure 3. A conceptual example of the upstream and downstream functional networks for a given barrier.\n\n\n \nBarriers that have been modelled are assumed to be barriers until field verification is undertaken and structures that have been assessed as “potential” barriers (e.g., may be passable at certain flow levels or for certain life history stages) require further investigation before a definitive remediation decision is made. Additionally, the habitat model will identify stream segments that have the potential to support spawning or rearing habitat for target species but does not attempt to quantify habitat quality or suitability, which will require additional field verification once barrier assessments have been completed. As such, the barrier prioritization process should be considered iterative and the initial list represents structures that are a priority to evaluate further through barrier assessment and habitat confirmations because some structures will likely be passable, others will not be associated with usable habitat, and others may not be feasible to remediate because of logistic considerations. Each time new information is required, the underlying datasets can be updated, and the abfishpass tools can be re-run to provide up-to-date results."
  },
  {
    "objectID": "software-docs.html",
    "href": "software-docs.html",
    "title": "3  License",
    "section": "",
    "text": "This section provides an overview of the model tools and how to run them."
  },
  {
    "objectID": "software-docs.html#abfishpass-software",
    "href": "software-docs.html#abfishpass-software",
    "title": "3  License",
    "section": "abfishpass software",
    "text": "abfishpass software\nLicence: Apache License, Version 2.0 http://www.apache.org/licenses/LICENSE-2.0\nCopyright: © 2022 Canadian Wildlife Federation, Alberta Environment and Parks"
  },
  {
    "objectID": "data-sources.html",
    "href": "data-sources.html",
    "title": "4  Data sources",
    "section": "",
    "text": "Fish and Wildlife Management Information System (FWMIS) - Fish Survey – Government of Alberta\nFWMIS - Aquatic Habitat – Government of Alberta\nFWMIS - Fish Stocking – Government of Alberta\nFWMIS - Hydrology Arcs – Government of Alberta\nBase Features Access Roads – Alberta Environment and Parks\nBase Features Access Railway – Alberta Environment and Parks\nDesignated Trails – Alberta Environment and Parks\nBarrier Inspection Data – Watercourse Crossing Program, AEP 1\nCanadian Aquatic Barriers Database – Canadian Wildlife Federation\n\n\n\n\n\n\n\nNote\n\n\n\nabfishpass is under active development and data sources may change over time.\n\n\n\n\n\n\n\nPending data-sharing agreements↩︎"
  },
  {
    "objectID": "requirements-config.html",
    "href": "requirements-config.html",
    "title": "5  Requirements and Configuration",
    "section": "",
    "text": "Python (tested with version 3.9.5)\n\nModules: shapely, psycopg2, tifffile\n\nGDAL/ORG (comes installed with QGIS or can install standalone)\nPostgreSQL/PostGIS database"
  },
  {
    "objectID": "requirements-config.html#configuration",
    "href": "requirements-config.html#configuration",
    "title": "5  Requirements and Configuration",
    "section": "5.2 Configuration",
    "text": "5.2 Configuration\nAll configuration is setup in the config.ini file. Before running any scripts you should ensure the information in this file is correct.\nAll of the scripts allow for a custom configuration file to be specified by providing it as the -c argument to the program. If not supplied, the default config.ini file will be used. For example:\nprompt> create_db.py -c custom_config.ini\n\nConfiguration File Definitions\n[OGR]\nogr = location of ogr2ogr executable\ngdalinfo = location of gdalinfo executable\ngdalsrsinfo = location of gdalsrsinfo executable\nproj = optional location of proj library\n\n[DATABASE]\nhost = database host\nport = database post\nname = database name\nuser = database username\npassword = database password\ndata_schema = name of main schema for holding raw stream data\nstream_table = names of streams table\nfish_species_table = name of fish species table\nworking_srid = the srid (3400) of the stream data - these scripts use the function st_length to compute stream length so the raw data should be in a meters based projection (or reprojected before used)\naquatic_habitat_table = table name for fish aquatic habitat data\nfish_stocking_table = table name for fish stocking data\nfish_survey_table = table name for fish survey data\n\n[CABD_DATABASE] - the barriers database for loading barrier data\nhost = CABD host name\nport = CABD port\nname = CABD database name\nuser = CABD username\npassword = CABD password\nbuffer = this is the buffer distance to grab features - the units are in the working_srid so if its meters 200 is reasonable, if it's degrees something like 0.001 is reasonable\nsnap_distance = distance (in working srid units) for snapping point features #to the stream network (fish observation data, barrier data etc)\n\n[CREATE_LOAD_SCRIPT]\nraw_data = raw alberta data\nroad_table = road table name\nrail_table = rail table name\ntrail_table = trail table name\n\n[PROCESSING]\nstream_table = stream table name\n\n[WATERSHEDID 1] -> there will be one section for each watershed with a unique section name\nwatershed_id = watershed id to process\noutput_schema = output schema name\nfish_observation_data = zip file containing fish observation data\n\n[WATERSHEDID 2] -> there will be one section for each watershed with a unique section name\nwatershed_id = watershed id to process\noutput_schema = output schema name\nfish_observation_data = zip file containing fish observation data\n\n[ELEVATION_PROCESSING]\ndem_directory = directory containing dem\n3dgeometry_field = field name (in streams table) for geometry that stores raw elevation data\nsmoothedgeometry_field = field name (in streams table) for geometry that stores smoothed elevation data\n\n[MAINSTEM_PROCESSING]\nmainstem_id = name of mainstem id field (in streams table)\ndownstream_route_measure = name of downstream route measure field\nupstream_route_measure =name upstream route measure field\n\n[GRADIENT_PROCESSING]\nvertex_gradient_table = table for storing vertex gradient values\nsegment_gradient_field = name of segment gradient field (in streams table)\nmax_downstream_graident_field = name of field for storing the maximum downstream segment gradient (in streams table)\n\n[BARRIER_PROCESSING]\nbarrier_table = table for storing barriers\n\n[MODELLED_CROSSINGS]\nmodelled_crossings_table = table for storing modelled crossings\nstrahler_order_barrier_limit = all crossings on streams with strahler order less than this will be considered barriers and treated similar to dams/waterfalls for habitat modelling\n\n[HABITAT_STATS]\nstats_table = this table will be created in the [DATABASE].data_schema schema and contain watershed statistics\n\nwatershed_data_schemas=ws17010302,ws17010301 --> this is the list of processing schemas to include in the stats the schemas must exist and data must be processed"
  },
  {
    "objectID": "data-loading.html",
    "href": "data-loading.html",
    "title": "6  Data Loading and Preparation",
    "section": "",
    "text": "The first step is to populate the database with the required data. These load scripts are specific to the data provided for Alberta. Different source data will require modifications to these tools. We are using an open-source PostgreSQL database to store and process the data.\nTools:\n\nload_alberta/create_db.py – this script creates all the necessary database tables\nload_alberta/load_alberta.py – this script uses OGR to load the provided Alberta data from the .gdb file into the PostgreSQL database.\n\n\n\nAs a part of the loading scripts a fish species table is created which contains the fish species of interest for modelling and various modelling parameters. Before processing the watershed these parameters should be reviewed and configured as necessary. See load_alberta/create_db.py.\n\n\n\n\n\n\nNote\n\n\n\nCurrently there is no velocity or channel confinement data. These parameters are placeholders for when this data is added."
  },
  {
    "objectID": "data-loading.html#watershed-processing",
    "href": "data-loading.html#watershed-processing",
    "title": "6  Data Loading and Preparation",
    "section": "6.2 Watershed Processing",
    "text": "6.2 Watershed Processing\nData preparation is completed by watershed ID, each watershed is processed into a separate schema in the database named after the watershed identifier (e.g., ws17010301 for the Berland River).\nCurrently preparation includes:\n\nPreprocessing step which loads all the streams from the raw datastore into the working schema\nLoading barrier datasets\nSnapping barriers to stream network and breaking the stream segements at these points\nLoading fish observation and habitat data\n\nCurrently processing includes:\n\nPreprocessing step which loads all the streams from the raw datastore into the working schema\nLoading barriers from the CABD barrier database\nComputing Modelled Crossings\nComputing Mainstems\n\nComputing an elevation values for all stream segments\nComputing a smoothed elevation value for all stream segments\nCompute gradient for each stream vertex based on vertex elevation and elevation 100m upstream.\nBreak stream segments at required locations\nReassign raw elevation, smoothed elevation to stream segments\nCompute segment gradient based on start, end elevation and length\nLoad and snap fish stocking and observation data to stream network\nCompute upstream/downstream statistics for stream network, including number of barriers, fish stocking species and fish survey species\nCompute accessibility models based on stream gradient and barriers\nCompute habitat models\nCompute upstream/downstream statistics for modelled crossings\n\n\n6.2.1 Main Watershed Processing Script\nTool: process_watershed.py\nThe Watershed Processing tool can be used by running the main processing script:\nprocess_watershed.py -c config.ini [watershedid]\nThis script calls and executes a series of individual process scripts (see section below). The watershedid field must be specified as a section header in the config.ini file. The section must describe the watershed processing details for example:\n[17010301]\n#Berland: 17010301\nwatershed_id = 17010301\noutput_schema = ws17010301\nfish_observation_data = C:\\temp\\fishobservationdata.zip\n\nInput Requirements:\n\nDirectory of tif images representing DEM files. All files should have the same projection and resolution.\nA raw streams table with id (uuid), name (varchar), strahler order (integer), watershed_id (varchar), and geometry (linestring) fields. The scripts assume this data is in an equal length projection so the st_length2d(geometry) function returns the length in metres.\n\n\n\nOutput:\n\nA new schema with a streams table, barrier, modelled crossings and other output tables.\n\n\n\n\n\n\n\nWarning\n\n\n\nALL EXISTING DATA IN THE OUTPUT TABLES WILL BE DELETED.\n\n\n\n\n\n6.2.2 Individual Processing Scripts\nThese scripts are the individual processing scripts that are used for the watershed processing steps.\n\n1. Preprocessing\nTool: preprocess_watershed.py\nThis script creates required database schemas, and loads stream data for the watershed into a working table in this schema.\n\nInput Requirements:\n\nRaw stream network dataset loaded\n\n\n\nOutput:\n\nA database schema named after the watershed ID\nA streams table in this schema populated with all streams from the raw dataset\n\n\n\n\n2. Loading Barriers\nTool: load_and_snap_barriers_cabd.py\nThis script loads waterfalls and dam barriers from the CABD database.\n\nInput Requirements:\n\nAccess to the CABD database\nStreams table populated from the preprocessing step\n\n\n\nOutput:\n\nA new barrier table populated with dam and waterfall barriers from the CABD database\nThe barrier table has two geometry fields - the raw field and a snapped field (the geometry snapped to the stream network). The maximum snapping distance is specified in the configuration file (default = 200 m).\n\n\n\n\n3. Compute Modelled Crossings\nTool: compute_modelled_crossings.py\nThis script computes modelled crossings, defined as locations where rail, road, or trails cross stream networks (based on feature geometries). Due to data errors, some of these crossings may not actually exists on the ground.\n\nInput Requirements:\n\nStreams table populated from the preprocessing step\nRoad, rail, and trail data loaded from the /load_alberta/ scripts\n\n\n\nOutput:\n\nA new modelled crossings table with a reference to the stream edge the crossing crosses.\nModelled crossings with strahler_order >= 6 are classified as sub_type of bridge and a passability status of PASSABLE\nUpdated barriers table that now includes modelled crossing that occur on streams with strahler order < 6\n\n\n\n\n\n\n\nNote\n\n\n\nAEP’s Watercourse Crossing Program maintains an inventory of inspections that have been performed by barrier owners under the program. We are currently negotiating a data-sharing agreement that would allow this data to be shared publicly, with some sensitive attributes witheld (e.g., specific ownership).\nBarrier inspection points will be matched to corresponding modelled stream crossings using a 150 m distance threshold (i.e., inspections points and modelled points within 150 m of each other will be matched). Unmatched inspection points will be manually review and matched, if possible.\n\n\n\n\n\n4. Compute Mainstems\nTool: compute_mainstems.py\nThis script computes mainstems based on the names of streams and/or longest upstream length.\n\nAlgorithm\nMainstems are computed by starting at the sink node and walking up the network. At any confluence the mainsteam is push up the edge that:\n\nHas the same stream name as the current edge\nIf no edges have the same name then any named edge; if there are multiple named edges it picks the edge with the longest path to a headwater\nIf no named edges; then it picks the edge with the longest path to a headwater.\n\n\n\nInput Requirements:\n\nStreams table\n\n\n\nOutput:\n\nThree new fields, mainstem_id, downstream_route_measure, and upstream_route_measure, added to the input table. The measure fields are calculated in metres.\n\n\n\n\n5. Assign Raw Z (Elevation) Values\nTool: assign_raw_z.py\nThis script “drapes” a stream network over provided DEMs and computes a raw Z (i.e., elevation) value for each vertex in the stream network.\n\nAlgorithm\nTo compute raw elevation, for each vertex:\n\nDrop the vertex on the DEM and determine which 4 cells are the nearest to the point. In the example below the four nearest cells to V are A, B, C, and D.\nCompute a bilinear interpolated value at this point using the values from cells A, B, C, and D.\n\nA = (x1, y2, Az)\nB = (x2, y2, Bz)\nC = (x1, y1, Cz)\nD = (x2, y1, Dz)\nV = (x, y, Vz)\n    \nfxy1 = ((x2 - x) / (x2- x1))*Cz + ((x - x1)/(x2 - x1))*Dz\nfxy2 = ((x2 - x) / (x2- x1))*Az + ((x - x1)/(x2 - x1))*Bz\nVz = ((y2 - y) / (y2 - y1))*fxy1 + ((y - y1)/(y2 - y1))*fxy2\n\n+-------------+-------------+\n|             |             |\n|             |             |\n|      A      |      B      |\n|             |             |\n|             |             |\n+-------------+-------------+\n|          V  |             |\n|             |             |\n|      C      |      D      |\n|             |             |\n|             |             |\n+-------------+-------------+\n\n\n\n\n\n\nNote\n\n\n\nwe assume that the elevation values provided in the DEM represent the elevation at the center point of the cell.\n\n\n\n\nInput Requirements:\n\nDirectory of .tiff images representing DEM files. All files should have the same projection and resolution.\nStreams table populated from the preprocessing step.\n\n\n\nOutput:\n\nA geometry_raw3d field added to the stream table that represents the 3d geometry for the segment.\n\n\n\n\n6. Compute Smoothed Z Values\nTool: smooth_z.py\nTakes a set of stream edges with raw z values and smooths them to enforce that the streams are always flowing down hill.\n\nAlgorithm\nThe smoothing process ensures streams always flow downhill.\n\n\n\n\n\n\nNote\n\n\n\n\nThis algorithm does not contain any spike detection, so if there is an error in the DEM that causes a significant spike in the stream network this will significantly affect the results.\nNodes and vertices with no elevation values NODATA, are ignored in the computation of the min/max values.\n\n\n\n\nCreate a graph of the nodes in the stream network\nStarting at the sink nodes and walking up the network computing a max_elevation value for each node. This value is the maximum of the node’s raw elevation and the downstream node elevation values\nStarting at the source nodes and walking down the network compute a min_elevation value for each node. This value is the minimum of the node’s raw elevation values and the upstream node elevation values.\nFor each node assign a smoothed elevation of the the average of the max_elevation and min_elevation\nFor each edge in the network\n\n\nclip all vertices elevations so they are no smaller or bigger than the z values at the end nodes\ncompute min/max elevations for each vertex then average the results to get smoothed value\n\n Node  Elevation   Min  Max   Smoothed\n  A       12       12   12    12\n  B       10       10   10    10\n  C       6        6    7     6.5\n  D       7        6    7     6.5      \n  F       8        8    8     8      \n  G       2        2    2     2\n  \n    A           B \n     \\         /\n      \\       /\n       \\     /\n        C---+\n        |      F\n        |     / \n        |    /\n        D---+\n        |\n        |\n        |\n        F\n        \n\n\nInput Requirements:\n\nStreams table with id and geometry_raw3d fields (output from the raw z processing)\n\n\n\nOutput:\n\nA new field, geometry_smoothed3d, added to the input table\n\n\n\n\n7. Compute Vertex Gradients\nTool: compute_vertex_gradient.py\nFor every stream vertex, this scripts takes the elevation at that point and the elevation along the mainstem at a point 100m upstream and computes the gradient based on those two elevations.\n\nInput Requirements:\n\nStreams table with smoothed elevation values.\n\n\n\nOutput:\n\nA new table (vertex_gradients) with a single point for every vertex with a gradient calculated. This table includes both the vertex geometry, upstream geometry and elevation values at both those locations.\n\n\n\n\n8. Break Streams\nTool: break_streams_at_barriers.py\nThis script breaks the stream network at “barriers” and recomputes necessary attributes.\n\nAlgorithm\nFor this script a barrier is considered to be: a cabd barrier (dam, waterfall), all modelled crossings, and the most downstream vertices with a gradient greater than minimum value specified in the fish_species table for the accessibility_gradient field in a collection of vertices with gradient values larger than this value.\nFor example if stream vertices has these gradient classes:\nx = gradient > 0.35\no = gradient < 0.35\nx-----x------o------o------x------x-------x-------o---->\n\n1-----2------3------4------5------6-------7-------8---->\nThen the stream edge would be split at vertices 2 and 7.\n\n\nInput Requirements:\n\nStreams table with smoothed elevation values\n\n\n\nOutput:\n\nA break_points table that lists all the locations where the streams were broken\nUpdated streams table with mainstem route measures recomputed (in km this time)\nUpdated modelled crossings table (stream_id is replaced with a stream_id_up and stream_id_down referencing the upstream and downstream edges linked to the point)\n\n\n\n\n9. Re-compute Raw and Smoothed Z Values\nRecompute z values again based on the raw data so any added vertices can be computed based on the raw data and not interpolated points. Re-run z-value smoothing algorithm.\n\n\n10. Compute Stream Segment Gradients\nTool: compute_segment_gradient.py\nThis script computes a stream segment gradient based on the smoothed elevation for the most upstream coordinate, most downstream coordinate, and the length of the stream segment.\n\nInput Requirements:\n\nStreams table with smoothed elevation values\n\n\n\nOutput:\n\nAddition of a segment_elevation field to the streams table\n\n\n\n\n11. Load and Snap Fish Observations\nTool: load_and_snap_fishobservation.py\nThis script loads fish observation data provided and snaps it to the stream network.\n\nInput Requirements:\n\nFish observation data\nStream network\n\n\n\nOutput:\n\nAddition of three tables: fish_aquatic_habitat, fish_stocking, and fish_survey"
  },
  {
    "objectID": "data-analysis.html",
    "href": "data-analysis.html",
    "title": "7  Data Analysis",
    "section": "",
    "text": "The data analysis tools are also called by the main processing script: process_watershed.py."
  },
  {
    "objectID": "data-analysis.html#individual-tools",
    "href": "data-analysis.html#individual-tools",
    "title": "7  Data Analysis",
    "section": "7.1 Individual Tools",
    "text": "7.1 Individual Tools\n\n1. Compute upstream and downstream barrier and fish species information\nTool: compute_updown_barriers_fish.py\nThis script computes a number of statistics for each stream segment:\n\nNumber of upstream and downstream barriers\nThe identifiers of the upstream and downstream barriers\nThe fish species stocked on the stream segment\nThe fish species which are stocked upstream and downstream of the stream segment\nThe fish species surveyed on the stream segment\nThe fish species which were surveyed upstream and downstream of the stream segment\n\n\nInput Requirements:\n\nFish observation data\nStream network\nBarriers table\n\n\n\nOutput:\n\nAddition of statistic fields to the stream network table\n\n\n\n\n2. Compute Accessibility Models\nTool: compute_gradient_accessibility.py\nThis script computes an accessibility value for each fish species for each stream segment based on:\n\nComputed gradient barriers\nMaximum accessibility gradient (specified in the fish_species table)\nBarrier location\nFish survey and stocking information\n\nBarriers include:\n\nCABD loaded barriers (dams, waterfalls)\nModelled crossing on stream with Strahler order < 6\n\nStream segments will be classified as:\n\nACCESSIBLE = all downstream gradients are less than the maximum gradient threshold for the given species and there are no barriers downstream (OR there are fish stocking or survey points upstream for the given species)\nPOTENTIAL ACCESSIBLE = all downstream gradients are less than the maximum gradient threshold for the given species, but there is a barrier downstream\nNOT ACCESSIBLE = any downstream gradient is great than the maximum gradient threshold for the given species\n\n\nInput Requirements:\n\nStream network\nBarriers Table\n\n\n\nOutput:\n\nAddition of an accessibility field for each fish species to the stream network table\n\n\n\n\n3. Compute Habitat Models\nTool: compute_habitat_models.py\nThis script computes a true/false value for the following habitat models for each stream segment, based on the following parameters and criteria:\n\nStream gradient\n\nWHERE stream_gradient stream_gradient ≥ min_gradient AND\nstream_gradient < max_gradient AND\nspecies_accessibility IN (ACCESSIBLE OR POTENTIALLY ACCESSIBLE)\n\nDischarge (m^3/s)\n\nWHERE stream_discharge ≥ min_discharge AND\nstream_discharge < max_discharge AND\nspecies_accessibility IN (ACCESSIBLE OR POTENTIALLY ACCESSIBLE)\n\nChannel confinement (ratio of valley width/channel width)\n\nAlways `true` for now, model to be defined later.\n\nInput Requirements:\n\nStream network\n\n\n\nOutput:\n\nAddition of habitat model fields for each species to stream network table\n\n\n\n\n4. Compute Barrier Statistics\nTool: compute_modelled_crossings_upstream_values.py\nThis script computes a collection of modelled crossing statistics for each species and habitat model, including:\n\nTotal accessible upstream length: total length of streams that are accessible upstream of this point\nTotal upstream habitat length: total upstream length with habitat model = true\nFunctional upstream habitat length: computed by walking up the stream network summing up length of stream segments with habitat model = true, stopping at the first barrier encountered on the mainstem and all potential tributaries (upstream)\n\n\nInput Requirements:\n\nStream network\nModelled crossing\nBarriers\n\n\n\nOutput:\n\nAddition of statistics fields to the modelled crossings table"
  }
]